{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e9fb5ff-1179-4b4d-8b25-fed249361c6f",
   "metadata": {},
   "source": [
    "# Lesson 5: Passive and active monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414d2d9d-cad1-4548-90c0-115ebb2a51ec",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c50b87ce-17a5-4cf3-8f90-4420f31df3fd",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13489fee-6538-4b50-8cc2-c873f7cc293b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import whylogs as why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41bc1e60-3db6-4059-be9d-7ef5015c6e4b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd4400b-6240-4a1a-8d45-a62d4d062f6f",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from langkit import llm_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd0cce47-ea95-4d2a-a8d6-4fa057db73cf",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<whylogs.experimental.core.udf_schema.UdfSchema at 0x7f40c1815ae0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_metrics.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b60e9758-1b61-4121-84f6-67c4bc072de0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from whylogs.experimental.core.udf_schema import register_dataset_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5885749-6f72-4200-9e20-0c3a8f303270",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from whylogs.experimental.core.udf_schema import udf_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10e3f81e-3ca1-4fad-9df3-6eae571543a6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "llm_schema = udf_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6275cf6-d3d7-4ba1-85b0-d0ba5da344f0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "llm_logger = why.logger(schema=udf_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63fa2886-c738-49a8-9d1e-d604d41d1eeb",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "llm_logger = why.logger(\n",
    "    model = \"rolling\",\n",
    "    interval = 1,\n",
    "    when = \"H\",\n",
    "    schema = udf_schema()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad41b3",
   "metadata": {},
   "source": [
    "**Note**: To accessthe WhyLabs platform that was built in the previous lessons: https://hub.whylabsapp.com/resources/model-1/profiles?profile=ref-EBT5yDFL0lyq0r93&sessionToken=session-pPdc5R9m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c366d6-dfe9-4ff0-8e8d-d4d5e167a5ce",
   "metadata": {},
   "source": [
    "## Building your own active monitoring guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08e675d9-05af-47ed-b852-0e652ca03030",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d9fce34-626b-41c7-a875-971b6b045106",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "openai.api_key = helpers.get_openai_key()\n",
    "openai.base_url = helpers.get_openai_base_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9fe03da-4065-40f3-9195-5321086ae7d4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "active_llm_logger = why.logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0290cec1-7961-45dc-8178-56541d1b1047",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "def user_request():\n",
    "    # Take request\n",
    "    request = input(\"\\nEnter your desired item to make a recipe\" \\\n",
    "                    \"(or 'quit'):\")\n",
    "    if request.lower() == \"quit\":\n",
    "        raise KeyboardInterrupt()\n",
    "        \n",
    "    # Log request\n",
    "    active_llm_logger.log({\"request\": request})\n",
    "\n",
    "    return request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33832180-d4e7-4167-a714-b9253c0747e3",
   "metadata": {
    "height": 404
   },
   "outputs": [],
   "source": [
    "def prompt_llm(request):\n",
    "    # Transform prompt\n",
    "    prompt = f\"\"\"Please give me a short recipe for creating\"\\\n",
    "    the following item in up to 6 steps. Each step of the recipe \"\\\n",
    "    should be summarized in no more than 200 characters.\"\\\n",
    "    Item: {request}\"\"\"\n",
    "\n",
    "    # Log prompt\n",
    "    active_llm_logger.log({\"prompt\": prompt})\n",
    "\n",
    "    # Collect response from LLM\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompt\n",
    "        }]\n",
    "    )[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    # Log response\n",
    "    active_llm_logger.log({\"response\": response})\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42b4b09d-0b47-4706-abe9-72edb04e4d35",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "def user_reply_success(request,response):\n",
    "    # Create and print user reply\n",
    "    reply = f\"\\nSuccess! Here is the recipe for \"\\\n",
    "            f\"{request}:\\n{response}\"\n",
    "    print(reply)\n",
    "\n",
    "    #Log reply\n",
    "    active_llm_logger.log({\"reply\": reply})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee5755da-f487-4bb5-abc2-4f75f19b972e",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "def user_reply_failure(request = \"your request\"):\n",
    "    # Create and print user reply\n",
    "    reply = (\"\\nUnfortunately, we are not able to provide a recipe for \" \\\n",
    "            f\"{request} at this time. Please try Recipe Creator 900 \" \\\n",
    "            f\"in the future.\")\n",
    "    print(reply)\n",
    "\n",
    "    #Log reply\n",
    "    active_llm_logger.log({\"reply\": reply})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dc3b03d-c87f-4d70-8ba2-f747e321266b",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "class LLMApplicationValidationError(ValueError):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "880760c1-bb08-4f99-81b8-6de02a80f119",
   "metadata": {
    "height": 183
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your desired item to make a recipe(or 'quit'):turkey\n",
      "\n",
      "Success! Here is the recipe for turkey:\n",
      "1. Preheat oven to 325°F.\n",
      "2. Pat dry whole turkey with paper towels, season with salt and pepper.\n",
      "3. Stuff turkey cavity with aromatics like onion, garlic, and herbs.\n",
      "4. Place turkey on a roasting rack in a roasting pan, breast side up.\n",
      "5. Roast turkey for about 13-15 minutes per pound, basting every 30 minutes.\n",
      "6. Turkey is done when thermometer inserted into the thickest part of the thigh registers 165°F. Let it rest before carving.\n",
      "\n",
      "Enter your desired item to make a recipe(or 'quit'):quit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        request = user_request()\n",
    "        response = prompt_llm(request)\n",
    "        user_reply_success(request, response)\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except LLMApplicationValidationError:\n",
    "        user_reply_failure(request)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee702c5e-78e9-41f1-a06a-744e3a173c11",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from whylogs.core.relations import Predicate\n",
    "from whylogs.core.metrics.condition_count_metric import Condition\n",
    "from whylogs.core.validators import ConditionValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d8e2065-d802-4dca-81b6-3d7137d786db",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "def raise_error(validator_name, condition_name, value):\n",
    "    raise LLMApplicationValidationError(\n",
    "        f\"Failed {validator_name} with value {value}.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af74ca18-002e-4afe-937c-520de465c569",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "low_condition = {\"<0.3\": Condition(Predicate().less_than(0.3))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de5f4609-932f-41de-a11d-38b8ca556967",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "toxicity_validator = ConditionValidator(\n",
    "    name = \"Toxic\",\n",
    "    conditions = low_condition,\n",
    "    actions = [raise_error]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82ef1e8c-064b-432c-bda4-c7f920b397dd",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "refusal_validator = ConditionValidator(\n",
    "    name = \"Refusal\",\n",
    "    conditions = low_condition,\n",
    "    actions = [raise_error]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b88ab523-88b2-4817-8a36-0a216e65583f",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "llm_validators = {\n",
    "    \"prompt.toxicity\": [toxicity_validator],\n",
    "    \"response.refusal_similarity\": [refusal_validator]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "182e8950-ccb1-43e6-886f-fe02d23a1b3d",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "active_llm_logger = why.logger(\n",
    "    model = \"rolling\",\n",
    "    interval = 5,\n",
    "    when = \"M\",\n",
    "    base_name = \"active_llm\",\n",
    "    schema = udf_schema(validators = llm_validators)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "809c648e-4d74-414c-b87e-eef694db46a0",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "ename": "LLMApplicationValidationError",
     "evalue": "Failed Refusal with value 0.5789185166358948.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLLMApplicationValidationError\u001b[0m             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mactive_llm_logger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mm sorry, but I can\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt answer that.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/whylogs/api/logger/logger.py:106\u001b[0m, in \u001b[0;36mLogger.log\u001b[0;34m(self, obj, pandas, row, schema, timestamp_ms, name)\u001b[0m\n\u001b[1;32m    103\u001b[0m profiles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_matching_profiles(obj, pandas\u001b[38;5;241m=\u001b[39mpandas, row\u001b[38;5;241m=\u001b[39mrow, schema\u001b[38;5;241m=\u001b[39mactive_schema)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prof \u001b[38;5;129;01min\u001b[39;00m profiles:\n\u001b[0;32m--> 106\u001b[0m     \u001b[43mprof\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpandas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecute_udfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     prof\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m    109\u001b[0m first_profile \u001b[38;5;241m=\u001b[39m profiles[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/whylogs/core/dataset_profile.py:117\u001b[0m, in \u001b[0;36mDatasetProfile.track\u001b[0;34m(self, obj, pandas, row, execute_udfs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_track_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_track\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpandas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecute_udfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecute_udfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/whylogs/core/dataset_profile.py:147\u001b[0m, in \u001b[0;36mDatasetProfile._do_track\u001b[0;34m(self, obj, pandas, row, execute_udfs)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns[k]\u001b[38;5;241m.\u001b[39m_track_datum(row[k], row\u001b[38;5;241m.\u001b[39mget(col_id))\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_columns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_track_datum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pandas \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# TODO: iterating over each column in order assumes single column metrics\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m#   but if we instead iterate over a new artifact contained in dataset profile: \"MetricProfiles\", then\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m#   each metric profile can specify which columns its tracks, and we can call like this:\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m#   metric_profile.track(pandas)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/whylogs/core/column_profile.py:74\u001b[0m, in \u001b[0;36mColumnProfile._track_datum\u001b[0;34m(self, value, identity_values)\u001b[0m\n\u001b[1;32m     72\u001b[0m     id_col \u001b[38;5;241m=\u001b[39m PreprocessedColumn\u001b[38;5;241m.\u001b[39m_process_scalar_value(identity_values)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m validator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_validators:\n\u001b[0;32m---> 74\u001b[0m     \u001b[43mvalidator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumnar_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_extracted_column(ex_col)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/whylogs/core/validators/condition_validator.py:90\u001b[0m, in \u001b[0;36mConditionValidator.columnar_validate\u001b[0;34m(self, data, identity_values)\u001b[0m\n\u001b[1;32m     88\u001b[0m                     action(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, cond_name, x, identity_list[index])  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     89\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m                     \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m=\u001b[39m count\n",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m, in \u001b[0;36mraise_error\u001b[0;34m(validator_name, condition_name, value)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_error\u001b[39m(validator_name, condition_name, value):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LLMApplicationValidationError(\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalidator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     )\n",
      "\u001b[0;31mLLMApplicationValidationError\u001b[0m: Failed Refusal with value 0.5789185166358948."
     ]
    }
   ],
   "source": [
    "active_llm_logger.log(\n",
    "    {\"response\":\"I'm sorry, but I can't answer that.\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb01aa07",
   "metadata": {},
   "source": [
    " ⚠️ **Disclaimer**: Please be aware that the code may not capture all safety concerns and some undesired responses can still pass through. We encourage you to explore ways in which you can make the monitoring system more robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78e61d-4ecc-4448-9592-ba157baef6a3",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        request = user_request()\n",
    "        response = prompt_llm(request)\n",
    "        user_reply_success(request, response)\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except LLMApplicationValidationError:\n",
    "        user_reply_failure(request)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c966f1ec-73aa-4df2-ad45-648a27977880",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

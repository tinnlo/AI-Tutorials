{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad96800d-eacf-474c-8e94-4b239266e963",
   "metadata": {},
   "source": [
    "# Prompt Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12069b71-c878-4199-8d7b-0ba469294742",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b7c6f4-67c2-4b9c-838f-4ae4c8c48b70",
   "metadata": {},
   "source": [
    "If you would like to view the utils.py file, uncomment the following line and run it. Alternately to view it in an editor, click `file->open` and look for utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "378a2aac-8aba-42c2-b98a-6260e9c866df",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "#!cat utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878c8b00-1f82-4ae8-973d-6775e8d1c14f",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6ff; padding:15px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\"> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>utils.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. For more help, please see the <em>\"Appendix - Tips and Help\"</em> Lesson.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f3131d-c1e0-4ce9-909b-222063cab03d",
   "metadata": {
    "id": "DC3VBQGs7ggW"
   },
   "source": [
    "## Using the \"user\" and \"assistant\" roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a39424b-ddc4-4a99-969d-270a06adf472",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Who wrote the book Charlotte's Web?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
     ]
    }
   ],
   "source": [
    "question = \"Who wrote the book Charlotte's Web?\"\n",
    "\n",
    "prompt = (\n",
    "    \"<|begin_of_text|>\"                              # start of prompt\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"       # user header\n",
    "    f\"{question}\"                                    # user input\n",
    "    \"<|eot_id|>\"                                     #end of turn\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"  #assistant header\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccfba2fe-8fa3-41b4-b91c-2f66dc6bfe5f",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The book \"Charlotte's Web\" was written by E.B. White.\n"
     ]
    }
   ],
   "source": [
    "from  utils import llama31\n",
    "response = llama31(prompt,8)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a7ffce6-514a-4e4a-acdf-ca65e49d2627",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"id\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"8da350770a0ccfe1-SJC\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"object\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"text.completion\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"created\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m1730206467\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"model\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"prompt\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m[],\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"choices\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m[\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"text\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"\\n\\nThe book \\\"Charlotte's Web\\\" was written by E.B. White.\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"finish_reason\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"eos\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"seed\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m9084371105746158000\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"logprobs\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34mnull\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"index\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m}\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m],\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"usage\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"prompt_tokens\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m17\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"completion_tokens\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m17\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"total_tokens\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m34\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m}\u001b[37m\u001b[39;49;00m\n",
      "}\u001b[37m\u001b[39;49;00m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import cprint\n",
    "response = llama31(prompt,8, raw=True)\n",
    "\n",
    "cprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8160c83-47d3-42b5-92fb-86f5fd97af51",
   "metadata": {},
   "source": [
    "# Multi-turn chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24c191c7-e158-4865-a80d-fade3d145d58",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "follow_up_question = \"Three best quotes in it\"\n",
    "follow_up_prompt = (\n",
    "    \"<|begin_of_text|>\"                              # start of prompt\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"        # past  \n",
    "    f\"{question}\"                                     # past\n",
    "    \"<|eot_id|>\"                                      # past\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"   # past\n",
    "    f\"{response}\"                                     # past\n",
    "    \"<|eot_id|>\"                                      # past\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"       # new\n",
    "    f\"{follow_up_question}\"                          # new\n",
    "    \"<|eot_id|>\"                                     # new\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"  # new\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e798493a-e9c8-4d96-8baf-f18c8bc8d2c6",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three of the most famous quotes from \"Charlotte's Web\" by E.B. White:\n",
      "\n",
      "1. **\"Alone we can do so little; together we can do so much.\"** - This quote highlights the theme of friendship and cooperation between Charlotte and Wilbur, the pig.\n",
      "\n",
      "2. **\"It is not often that someone comes along who is a true friend and a good writer. Charlotte was both.\"** - This quote emphasizes the special bond between Charlotte and Wilbur, and Charlotte's unique qualities as a friend and writer.\n",
      "\n",
      "3. **\"Where there is much light, the shadows disappear.\"** - This quote suggests that when there is kindness, understanding, and compassion (light), the negative aspects of life (shadows) fade away. This theme is reflected in the story as Charlotte's friendship with Wilbur brings joy and happiness to those around her.\n",
      "\n",
      "These quotes capture the essence of the story and its themes of friendship, kindness, and the power of words.\n"
     ]
    }
   ],
   "source": [
    "follow_up_response = llama31(follow_up_prompt)\n",
    "print(follow_up_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb293be0-612e-48df-b74a-d4d2d98ca8b2",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are three of the most famous quotes from \"Charlotte's Web\" by E.B. White:\n",
       "\n",
       "1. **\"Alone we can do so little; together we can do so much.\"** - This quote highlights the theme of friendship and cooperation between Charlotte and Wilbur, the pig.\n",
       "\n",
       "2. **\"It is not often that someone comes along who is a true friend and a good writer. Charlotte was both.\"** - This quote emphasizes the special bond between Charlotte and Wilbur, and Charlotte's unique qualities as a friend and writer.\n",
       "\n",
       "3. **\"Where there is much light, the shadows disappear.\"** - This quote suggests that when there is kindness, understanding, and compassion (light), the negative aspects of life (shadows) fade away. This theme is reflected in the story as Charlotte's friendship with Wilbur brings joy and happiness to those around her.\n",
       "\n",
       "These quotes capture the essence of the story and its themes of friendship, kindness, and the power of words."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(follow_up_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6036cfb-876b-4487-8325-33f03b4ff085",
   "metadata": {},
   "source": [
    "#### Without message history\n",
    "This is not in the video, but you can try the same prompt *Without* including history and see the models responds with three quotes - but not from the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "899eba88-632f-4ff9-bae6-8a5831284bfa",
   "metadata": {
    "height": 183
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "Here are three best quotes:\n",
       "\n",
       "1. **\"Believe you can and you're halfway there.\"** - Theodore Roosevelt\n",
       "\n",
       "This quote emphasizes the importance of having a positive mindset and believing in oneself. It suggests that having confidence and faith in one's abilities can lead to success.\n",
       "\n",
       "2. **\"The only way to do great work is to love what you do.\"** - Steve Jobs\n",
       "\n",
       "This quote highlights the significance of passion and enjoyment in one's work. It suggests that when we love what we do, we are more likely to be motivated, inspired, and produce high-quality work.\n",
       "\n",
       "3. **\"Success is not final, failure is not fatal: It is the courage to continue that counts.\"** - Winston Churchill\n",
       "\n",
       "This quote emphasizes the importance of perseverance and resilience in the face of challenges. It suggests that success is not a permanent state, and that failure is not a defining moment, but rather it's the courage to keep going that truly matters."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"Three Best quotes\"\n",
    "prompt = (\n",
    "    \"<|begin_of_text|>\"  \n",
    "    \"<|start_header_id|>user<|end_header_id|>\"\n",
    "    f\"{question}\"\n",
    "    \"<|eot_id|>\"\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"\n",
    ")\n",
    "response = llama31(prompt,8)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0f383-4115-44d5-9a58-62463ec5cbfb",
   "metadata": {},
   "source": [
    "## Using \"system\" role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fed0d3ce-a42b-446b-8a88-a4cefb185acc",
   "metadata": {
    "height": 336
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "* \"Champions are made from something they have deep inside them - a desire, a dream, a vision.\" - Muhammad Ali\n",
       "* \"It's not whether you get knocked down, it's whether you get up.\" - Vince Lombardi\n",
       "* \"Hard work, dedication, and a willingness to learn are the keys to success in any field, including sports.\" - Michael Jordan"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"Three Great quotes\"\n",
    "system_message = (\n",
    "    \"You are an expert in quotes about sports \" \n",
    "    \"You provide just the quotes and no commentary. \"\n",
    "    \"Reply in markdown\"\n",
    ")\n",
    "\n",
    "prompt = (\n",
    "    \"<|begin_of_text|>\"\n",
    "    \"<|start_header_id|>system<|end_header_id|>\"\n",
    "    f\"{system_message}\"\n",
    "    \"<|eot_id|>\"    \n",
    "    \"<|start_header_id|>user<|end_header_id|>\"\n",
    "    f\"{question}\"\n",
    "    \"<|eot_id|>\"\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"\n",
    ")\n",
    "response = llama31(prompt,70)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f5c210f-080b-4fe1-8a7b-7ff38d0ae9c8",
   "metadata": {
    "height": 336
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "* \"The only way to get started is to quit talking and begin doing.\" - John \"Hi\" Patterson\n",
       "* \"It's not about being the best, it's about being better than you were yesterday.\" - Bo Jackson\n",
       "* \"Don't watch the ball go through the hoop, watch the player.\" - John Wooden"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "follow_up_question = \"three more\"\n",
    "follow_up_prompt = (\n",
    "    \"<|begin_of_text|>\"\n",
    "    \"<|start_header_id|>system<|end_header_id|>\"      # system\n",
    "    f\"{system_message}\"                               # system\n",
    "    \"<|eot_id|>\"                                      # system\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"        # past\n",
    "    f\"{question}\"                                     # past\n",
    "    \"<|eot_id|>\"                                      # past\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"   # past\n",
    "    f\"{response}\"                                     # past\n",
    "    \"<|eot_id|>\"                                      # past\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"         # new\n",
    "    f\"{follow_up_question}\"                            # new     \n",
    "    \"<|eot_id|>\"                                       # new\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"    # new\n",
    ")\n",
    "response = llama31(follow_up_prompt)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139ecab0-a233-414e-a62d-dfb7b6bfbeef",
   "metadata": {},
   "source": [
    "# Chat with Llama using higher-level message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67920bea-5b75-4a42-a3a0-0aae77bc0842",
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The book \"Charlotte's Web\" was written by E.B. White.\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"<|begin_of_text|>\"                              # start of prompt\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"       # user header\n",
    "    \"Who wrote the book Charlotte's Web?\"                                    # user input\n",
    "    \"<|eot_id|>\"                                     #end of turn\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"  #assistant header\n",
    ")\n",
    "response = llama31(prompt,8)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58aa6676-3f4b-4d26-b679-ce392ec73845",
   "metadata": {
    "height": 149,
    "id": "nw9GEik8PWrx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book \"Charlotte's Web\" was written by E.B. White.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Who wrote the book Charlotte's Web?\"\n",
    "    }\n",
    "  ]\n",
    "response = llama31(messages,8)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67d3c1da-383e-423c-a1e8-d2c355febde0",
   "metadata": {
    "height": 404
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three notable quotes from \"Charlotte's Web\":\n",
      "\n",
      "1. \"Alone, you belong to no man. When you stand at the edge of a forest, it is like standing at the edge of all the days that ever have been. You are a part of all of them, and all of you are still unwritten.\"\n",
      "2. \"It is not often that someone comes along who is a true friend and a good writer. Charlotte was both.\"\n",
      "3. \"Wherever you live, be sure to make friends with someone who has less than you do. Help him, comfort him, love him, and stand by him.\"\n"
     ]
    }
   ],
   "source": [
    "follow_up_question = \"Three Best quotes\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You are an terse expert in children's literature\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Who wrote the book Charlotte's Web?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": response\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": follow_up_question\n",
    "    }\n",
    "  ]\n",
    "\n",
    "response = llama31(messages,8)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01b98689-fa40-4466-86f7-4ac17e206d81",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.messages = []\n",
    "        if system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "    def generate(self, user_question, model=8, temp=0):\n",
    "        self.messages.append({\"role\": \"user\", \"content\":user_question})\n",
    "        response = llama31(self.messages, model, temperature=temp)\n",
    "        self.messages.append({\"role\":\"assistant\", \"content\":response})\n",
    "        return response\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7479e19b-8270-4368-9bd9-cdeed5ed5664",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E.B. White wrote the book \"Charlotte\\'s Web\".'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"You are a terse expert in Childrens literature.\" \n",
    "conv = Conversation(system_message)\n",
    "conv.generate(\"Who wrote the book Charlotte's Web?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da3f5c43-262a-4b40-b00f-e6af7269e3eb",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are three quotes from \"Charlotte's Web\":\n",
       "\n",
       "1. \"Wherever you go, go there with all your heart.\"\n",
       "2. \"It's not often that someone comes along who is a true friend and a good writer. Charlotte was both.\"\n",
       "3. \"You have been my friend. That in itself is a tremendous thing.\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = conv.generate(\"What are three quotes\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be4e57bc-f77d-40f2-9b92-36c4dd8f8756",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a terse expert in Childrens literature.'},\n",
       " {'role': 'user', 'content': \"Who wrote the book Charlotte's Web?\"},\n",
       " {'role': 'assistant',\n",
       "  'content': 'E.B. White wrote the book \"Charlotte\\'s Web\".'},\n",
       " {'role': 'user', 'content': 'What are three quotes'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Here are three quotes from \"Charlotte\\'s Web\":\\n\\n1. \"Wherever you go, go there with all your heart.\"\\n2. \"It\\'s not often that someone comes along who is a true friend and a good writer. Charlotte was both.\"\\n3. \"You have been my friend. That in itself is a tremendous thing.\"'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d68ae5-31e7-4ebc-9100-88be9470ee45",
   "metadata": {
    "id": "5QntbEMl9uO5"
   },
   "source": [
    "## Multi-lingual Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4842cb63-d0b6-487c-b9ed-38f6e86b7ea0",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are 3 basic phrases in 8 languages:\n",
       "\n",
       "**English**\n",
       "1. Hello - Hello\n",
       "2. Thank you - Thank you\n",
       "3. Goodbye - Goodbye\n",
       "\n",
       "**German**\n",
       "1. Hallo - Hello\n",
       "2. Danke - Thank you\n",
       "3. Auf Wiedersehen - Goodbye\n",
       "\n",
       "**French**\n",
       "1. Bonjour - Hello\n",
       "2. Merci - Thank you\n",
       "3. Au revoir - Goodbye\n",
       "\n",
       "**Italian**\n",
       "1. Ciao - Hello/Goodbye\n",
       "2. Grazie - Thank you\n",
       "3. Arrivederci - Goodbye\n",
       "\n",
       "**Portuguese**\n",
       "1. Ol√° - Hello\n",
       "2. Obrigado/Obrigada - Thank you (male/female)\n",
       "3. Tchau - Goodbye\n",
       "\n",
       "**Hindi**\n",
       "1. ‡§®‡§Æ‡§∏‡•ç‡§§‡•á (Namaste) - Hello\n",
       "2. ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶ (Dhanyavad) - Thank you\n",
       "3. ‡§Ö‡§≤‡§µ‡§ø‡§¶‡§æ (Alvida) - Goodbye\n",
       "\n",
       "**Spanish**\n",
       "1. Hola - Hello\n",
       "2. Gracias - Thank you\n",
       "3. Adi√≥s - Goodbye\n",
       "\n",
       "**Thai**\n",
       "1. ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ (Sawatdee) - Hello\n",
       "2. ‡∏Ç‡∏≠‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì (Khop Khun Krap/Khob Kun Kha) - Thank you (male/female)\n",
       "3. ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö/‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞ (Sawatdee Krap/Sawatdee Ka) - Goodbye (male/female)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = (\n",
    "    \"Answer in 8 languages: English, German, French, Italian,\" \n",
    "    \"Portuguese, Hindi, Spanish, and Thai\"\n",
    ")\n",
    "ml_conv = Conversation(system_message)\n",
    "response = ml_conv.generate(\"3 basic phrases\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2bd3d8-c291-4edd-9b60-8a3faffc5100",
   "metadata": {},
   "source": [
    "## Chatbot App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dda1354e-b37b-491e-a7f5-c2bb397d14d5",
   "metadata": {
    "height": 523
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a Python script for a Gradio chatbot app that can be run within a Jupyter notebook:\n",
      "\n",
      "```python\n",
      "import gradio as gr\n",
      "\n",
      "# Initialize the Conversation class with a system message\n",
      "conversation = Conversation(\"You are an expert in literature. You provide brief replies.\")\n",
      "\n",
      "# Define a function to handle user input\n",
      "def chatbot(user_input, model_size, temperature):\n",
      "    # Generate a response using the Conversation class\n",
      "    response = conversation.generate(user_input, model=model_size, temp=temperature)\n",
      "    return response\n",
      "\n",
      "# Create a Gradio interface for the chatbot\n",
      "demo = gr.Interface(\n",
      "    fn=chatbot,\n",
      "    inputs=[\n",
      "        gr.Textbox(label=\"User Input\"),\n",
      "        gr.Radio(label=\"Model Size\", choices=[8, 70, 405], value=8),\n",
      "        gr.Slider(label=\"Temperature\", minimum=0, maximum=1, step=0.1, value=0)\n",
      "    ],\n",
      "    outputs=gr.Textbox(label=\"Chatbot Response\"),\n",
      "    title=\"Literature Expert Chatbot\",\n",
      "    description=\"Ask a question about literature and get a brief response.\"\n",
      ")\n",
      "\n",
      "# Launch the Gradio app\n",
      "demo.launch()\n",
      "```\n",
      "\n",
      "To run this script within a Jupyter notebook, simply copy and paste the code into a new cell and execute it. The Gradio app will launch in a new window, allowing you to interact with the chatbot.\n",
      "\n",
      "Note: Make sure you have the `gradio` library installed in your Jupyter notebook environment. You can install it using `!pip install gradio` or `!conda install -c conda-forge gradio`.\n"
     ]
    }
   ],
   "source": [
    "code_query = \"\"\"\n",
    "I need a Python script for a Gradio chatbot app that should be run\n",
    "within a Jupyter notebook.\n",
    "1) When calling the LLM, use this class, which is already defined,\n",
    "    dont redefine it:\n",
    "class Conversation:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.messages = []\n",
    "        if system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def generate(self, user_question, model=8, temp=0):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_question})\n",
    "        response = llama31(self.messages, model, temperature=temp)  \n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "        return response\n",
    "2) initialize the class with a system message of:\n",
    "    \"You are an expert in liturature. You provide brief replies\"\n",
    "3) the llama() function is defined like this:\n",
    "    def llama(prompt_or_messages, model_size=8, \n",
    "              temperature=0, raw=False, debug=False):\n",
    "    and returns a reponse in a string. Don't redefine this.\n",
    "    valid model sizes are 8, 70 and 405.\n",
    "\"\"\"\n",
    "coder_system_message = (\n",
    "    \"You are an expert writing python Gradio chatbots\" \n",
    ")\n",
    "coder_conv = Conversation(coder_system_message)\n",
    "response = coder_conv.generate(code_query, 405)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43dd04e2-0986-41f7-9b44-21459445d3d8",
   "metadata": {
    "height": 659
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  https://0.0.0.0:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://s172-29-85-119p7860.lab-aws-production.deeplearning.ai/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the code generated by Llama in the video\n",
    "# Your response to the above prompt may differ - try running your response as well!\n",
    "# note, the final line was hand edited to add \"server_name=\"0.0.0.0\" to run in the course environment\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "# Initialize the conversation with a system message\n",
    "conversation = Conversation(\"You are an expert in literature. You provide brief replies.\")\n",
    "\n",
    "# Define a function to generate a response to the user's input\n",
    "def generate_response(user_input, model_size, temperature):\n",
    "    try:\n",
    "        model_size = int(model_size)\n",
    "        if model_size not in [8, 70, 405]:\n",
    "            return \"Invalid model size. Please choose from 8, 70, or 405.\"\n",
    "        temperature = float(temperature)\n",
    "        if temperature < 0 or temperature > 1:\n",
    "            return \"Invalid temperature. Please choose a value between 0 and 1.\"\n",
    "        response = conversation.generate(user_input, model=model_size, temp=temperature)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Create a Gradio interface for the chatbot\n",
    "demo = gr.Interface(\n",
    "    fn=generate_response,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"User Input\"),\n",
    "        gr.Radio(label=\"Model Size\", choices=[\"8\", \"70\", \"405\"]),\n",
    "        gr.Slider(label=\"Temperature\", minimum=0, maximum=1, step=0.1, value=0)\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Response\"),\n",
    "    title=\"Literature Expert Chatbot\",\n",
    "    description=\"Ask a question about literature and get a brief response from an expert.\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio app\n",
    "demo.launch(server_name=\"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57bf3f4-63b5-45c7-943d-432e25376dd4",
   "metadata": {},
   "source": [
    "# A few more examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e79366c-678e-4f95-9bc7-520296fd9d54",
   "metadata": {
    "id": "Fz1IIJXajf77"
   },
   "source": [
    "## Compare with different sized Llama chat models\n",
    "\n",
    "By default, the llama31 call uses the Llama 3.1 8B Instruct model. To see how the 70B or 405B model responds, simply pass 70 or 405 after prompt. For example, let compare how the 3 different sized Llama 3.1 chat models respond to the question about a quote in Hemingway's classic The Old Man and the Sea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b420f914-9100-404d-bb66-22bc362774ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 149,
    "id": "f_WT9xQwaFbw",
    "outputId": "e40261ab-2c49-43fe-ec55-e1e5f658b26a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The quote you're thinking of is likely from Ernest Hemingway's novella \"The Old Man and the Sea\". The quote \"Everything about him was old except his eyes\" is the opening sentence of the book.\n"
     ]
    }
   ],
   "source": [
    "question = \"The quote that starts with 'Everything about him is old' in The Old Man and the Sea\"\n",
    "\n",
    "prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "\n",
    "response = llama31(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8019206b-dc6d-4a10-92d1-21b7dd30f528",
   "metadata": {
    "id": "OzlDWmD9koc9"
   },
   "source": [
    "If you like Hemingway, you know Llama 3.1 8B is hallucinating a bit, and \"old before they were young\"? Now try to see if 70B does better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d73d605-872a-417a-ab06-4854670f2966",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 47,
    "id": "_pZ80oupaFeX",
    "outputId": "ea30acaf-8c39-49fb-b9ba-34cc1f08610b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The quote you're thinking of is:\n",
      "\n",
      "\"Everything about him was old except his eyes and they seemed to possess a deep and unutterable wisdom.\"\n",
      "\n",
      "This is from the opening paragraph of Ernest Hemingway's novella \"The Old Man and the Sea\".\n"
     ]
    }
   ],
   "source": [
    "response = llama31(prompt, 70)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5812ce-a099-47fc-b57b-e233c40e9498",
   "metadata": {
    "id": "Rnyukk3GlHAX"
   },
   "source": [
    "The response makes more sense, but definitely not Hemingway would've written. In fact, it'd hurt the eyes of his fans. Let's hope 405 will cure the pain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ad1bace-7b20-429f-bb56-5b542c8a6567",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 47,
    "id": "dIHVm7ralEo0",
    "outputId": "b72f8dc8-6142-46a2-f25c-73c6d5f168a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "You're thinking of the famous quote from Ernest Hemingway's \"The Old Man and the Sea\"!\n",
      "\n",
      "The full quote is:\n",
      "\n",
      "\"Everything about him was old except his eyes and they were the same color as the sea and were cheerful and undefeated.\"\n",
      "\n",
      "Isn't that a beautiful and poignant description of the old man, Santiago?\n"
     ]
    }
   ],
   "source": [
    "response = llama31(prompt, 405)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b25935-0914-485b-86dc-3d9f11398a98",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
